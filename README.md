# vidXiv: Paper to Video

## 1. Paper Ingestion
- **Input**: Upload PDF or enter DOI  
- **Parse**: Extract raw text using tools like `pdfplumber` or `PyMuPDF`  
- **Optional**: Pull metadata from arXiv or Semantic Scholar for added context

---

## 2. Section Mapping (LLM-Orchestrated Storyboard)
- **Goal**: Identify key storytelling beats  
- **LLM Breakdown**: Auto-split into:
  - Hook  
  - Intro (big picture)  
  - Methods (visualizable logic)  
  - Results (key outcomes)  
  - Conclusions (insight)  
  - Takeaways + Further Reading  
- **Customizable**: Adjust style/depth based on audience (e.g., high schooler vs PhD)

---

## 3. Storyboard Design
For each section:
1. **Narration Draft**  
   - Bullet-point narration: clear, concise, and pedagogical  
2. **Visual Plan**  
   - Match each bullet with a visual: diagram, animation, data chart  
   - Specify style and medium (e.g. ManimCE, D3, schematic)

> âš ï¸ **Rule**: Write narration *first*, then design visuals â€” not the other way around.

---

## 4. Asset Generation

### a. Voiceover
- Finalize script  
- Generate audio via ElevenLabs, Bark, or OpenVoice

### b. Visuals
- Use LLM (e.g. Gemini 1.5 Pro) to:
  - Translate visual prompts to object-oriented **ManimCE** code  
  - Auto-debug + render scenes  
  - Second-pass refinement via frame-by-frame LLM QA  

---

## 5. Video Assembly
- Stitch visuals + voice using `moviepy` or `ffmpeg`  
- Add transitions, title cards, intro/outro, lower-thirds  
- Optional: Add music bed, captions, or dynamic text

---

## 6. Export & QA
- **Output**: Final MP4  
- **Review**: Manual watch-through or LLM-based QA for pacing, clarity  
- **Delivery**: Publish to platform or return to user

---

## Coming Soon
- Extract diagrams, figures, and tables from PDFs  
- Auto-citation + source credits  
- Style presets: â€œ3Blue1Brown,â€ â€œKurzgesagt,â€ â€œCrashCourseâ€  
- Auto-upload to YouTube (title, thumbnail, description)  
- Auto-generate summary notes or viewer quiz

---

## Stretch Vision
- ğŸ” Feedback loops from viewers â†’ LLM tuning for better future videos  
- ğŸ“š Multi-paper â€œState of the Fieldâ€ synthesis videos  
- ğŸ¤ Researcher-facing tool: upload your paper â†’ get editable video draft